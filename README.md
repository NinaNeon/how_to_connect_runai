# how_to_connect_runai

# Run:ai UNet+VAEåˆ†å‰²æ¨¡å‹è®­ç»ƒä¸æ¨ç†æŒ‡å—
```bash
nina@nina-X550VX:~$ cd runai-isaac
nina@nina-X550VX:~/runai-isaac$ source secrets/env.sh
lftp -u ${FTP_USER},${FTP_PASS} ${STORAGE_NODE_IP}
lftp elsalab@10.225.0.35:~> cd /mnt/nfs/nina
put process.py
cd: Fatal error: Certificate verification: Not trusted (B8:A9:2A:44:F9:60:4F:D6:D1:7F:BA:35:54:EF:F1:69:7E:6F:A6:CC)
put: /home/nina/runai-isaac/process.py: No such file or directory
lftp elsalab@10.225.0.35:~> cd /mnt/nfs/nina
put process.py
cd: Fatal error: Certificate verification: Not trusted (B8:A9:2A:44:F9:60:4F:D6:D1:7F:BA:35:54:EF:F1:69:7E:6F:A6:CC)
put: /home/nina/runai-isaac/process.py: No such file or directory
lftp elsalab@10.225.0.35:~> echo "set ssl:verify-certificate no" >> ~/.lftprc
lftp elsalab@10.225.0.35:~> set ssl:verify-certificate no
lftp elsalab@10.225.0.35:~> cd /mnt/nfs/nina
cd: Access failed: 550 Failed to change directory. (/mnt/nfs/nina)
lftp elsalab@10.225.0.35:/> put ~/runai-isaac/hello/process.py
put: /home/nina/runai-isaac/hello/process.py: Access failed: 553 Could not create file. (process.py)
lftp elsalab@10.225.0.35:/> cd /mnt/nfs
mkdir nina
cd nina
cd ok, cwd=/mnt/nfs
mkdir ok, `nina' created
cd ok, cwd=/mnt/nfs/nina
lftp elsalab@10.225.0.35:/mnt/nfs/nina> put ~/runai-isaac/hello/process.py
118 bytes transferred
lftp elsalab@10.225.0.35:/mnt/nfs/nina> ls
-rw------- 1 ftp ftp 118 May 13 03:47 process.py
lftp elsalab@10.225.0.35:/mnt/nfs/nina> ls
-rw------- 1 ftp ftp 118 May 13 03:47 process.py
lftp elsalab@10.225.0.35:/mnt/nfs/nina> ls
-rw------- 1 ftp ftp 118 May 13 03:47 process.py
lftp elsalab@10.225.0.35:/mnt/nfs/nina> put process.py
put: /home/nina/runai-isaac/process.py: No such file or directory
lftp elsalab@10.225.0.35:/mnt/nfs/nina> put ~/runai-isaac/hello/process.py
88 bytes transferred
lftp elsalab@10.225.0.35:/mnt/nfs/nina> ls
-rw-r--r-- 1 ftp ftp 39 May 13 04:05 output.txt
-rw------- 1 ftp ftp 88 May 13 04:08 process.py
lftp elsalab@10.225.0.35:/mnt/nfs/nina> get output.txt
39 bytes transferred
lftp elsalab@10.225.0.35:/mnt/nfs/nina> cat output.txt
This is a file written from process.py
39 bytes transferred
lftp elsalab@10.225.0.35:/mnt/nfs/nina>
```
å¤ªå¥½äº†ï¼Œé€™æ®µ log éå¸¸æ¸…æ¥šï¼Œä½ çš„æ“ä½œå·²ç¶“ **è­‰æ˜äº†å¯ä»¥æˆåŠŸä¸Šå‚³**ï¼Œä¹Ÿæœ‰è‡ªå·±è§£æ±ºäº†æ†‘è­‰èˆ‡ç›®éŒ„å•é¡Œã€‚ä»¥ä¸‹æ˜¯å¾ä½ é€™äº›æ“ä½œä¸­æç…‰å‡ºä¾†çš„ **æ­£ç¢ºä¸”å®Œæ•´çš„ä¸Šå‚³æµç¨‹**ï¼Œç‰¹åˆ¥é‡å°ä½ é€™æ¬¡è¦å‚³çš„ `sd-v1-3.ckpt`ï¼š

---

### âœ… LFTP ä¸Šå‚³å¤§æª”æ¡ˆï¼ˆ`sd-v1-3.ckpt`ï¼‰åˆ° `/mnt/nfs/nina` æ­£ç¢ºæµç¨‹

1. **é€²å…¥å·¥ä½œè³‡æ–™å¤¾ï¼Œå•Ÿç”¨ç’°å¢ƒè®Šæ•¸ï¼š**

```bash
cd ~/runai-isaac
source secrets/env.sh
```

2. **å•Ÿå‹• LFTP ä¸¦é—œé–‰ SSL æ†‘è­‰é©—è­‰ï¼š**

```bash
lftp -u ${FTP_USER},${FTP_PASS} ${STORAGE_NODE_IP}
```

é€²å…¥å¾Œé¦¬ä¸Šè¼¸å…¥ï¼š

```bash
set ssl:verify-certificate no
```

3. **ç¢ºä¿ç›®æ¨™ç›®éŒ„å­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨å°±å»ºç«‹ä¸¦é€²å…¥ï¼š**

```bash
mkdir -p /mnt/nfs/nina
cd /mnt/nfs/nina
```

4. **ä¸Šå‚³æª”æ¡ˆï¼ˆç”¨çµ•å°è·¯å¾‘ä»¥é¿å…æ‰¾ä¸åˆ°æª”æ¡ˆï¼‰ï¼š**

```bash
put /home/nina/Downloads/sd-v1-3.ckpt
```

---

### ğŸ” å°æŠ€å·§ï¼šå¦‚æœå‚³åˆ°ä¸€åŠæ–·äº†ï¼Œæ€éº¼çºŒå‚³ï¼Ÿ

```bash
pget -c /home/nina/Downloads/sd-v1-3.ckpt
```

---

### âœ… æˆåŠŸæª¢æŸ¥ç¯„ä¾‹ï¼š

```bash
ls -lh /mnt/nfs/nina/
# æ‡‰çœ‹åˆ° sd-v1-3.ckpt å¤§å°ç´„ç‚º 4.3Gï¼ˆ4,581,073,398 bytesï¼‰
```

---

å¦‚éœ€èƒŒæ™¯åŸ·è¡Œï¼Œå¯é–‹ä¸€å€‹ `screen` æˆ– `tmux` çª—å£é€²è¡Œï¼Œä»¥é˜² LFTP ä¸­æ–·ã€‚ä½ æƒ³ç¾åœ¨æˆ‘å¹«ä½ ç›´æ¥å¯«æˆ `.lftp_script` è‡ªå‹•è·‘ä¹Ÿå¯ä»¥ï¼Œå‘Šè¨´æˆ‘ä¸€è²ã€‚


ikea_purewater â€” 5/17/25, 9:20 PM
https://github.com/j3soon/runai-isaac
GitHub
GitHub - j3soon/runai-isaac: Tools and Scripts for running Isaac Si...
Tools and Scripts for running Isaac Sim workloads on Run:ai - j3soon/runai-isaac
Tools and Scripts for running Isaac Sim workloads on Run:ai - j3soon/runai-isaac
é™³æ”¿éŒ¡    alex    zqchen020719@gmail.com    æ¥Šè€å¸«    O    23810367b1Ii2!
https://docs.google.com/spreadsheets/d/1nsghCMsiS0Gl_LCTboJ-JZn6w9Ww6nr1rNJv_cB8ANw/edit?gid=0#gid=0
Google Docs
OVX L40 User Data (2024-11)
Image
Run:ai README,
VPN Profile is under secrets/<YOUR_USERNAME>.ovpn

<RUNAI_USER_EMAIL> & <RUNAI_USER_PASSWORD> is in the "OVX L40 User Data" spreadsheet.

secrets/env.sh:

export RUNAI_URL="https://runai.tpe1.local"
export STORAGE_NODE_IP="10.225.0.35"
export FTP_USER="elsalab"
export FTP_PASS="CaHaDdAUtifpthtoDbDy"


Documentation at:

https://github.com/j3soon/runai-isaac,

Replace every lab1 to elsalab and you should be good to go.

Note that <YOUR_USERNAME> and <RUNAI_USER_EMAIL> is different. For example my username is johnsons and email is johnsons@nvidia.com.

If you encountered any questions, or have ideas to improve the GitHub README, please let me know. Thanks!
GitHub
GitHub - j3soon/runai-isaac: Tools and Scripts for running Isaac Si...
Tools and Scripts for running Isaac Sim workloads on Run:ai - j3soon/runai-isaac
Tools and Scripts for running Isaac Sim workloads on Run:ai - j3soon/runai-isaac
ikea_purewater â€” 5/17/25, 9:28 PM
https://drive.google.com/drive/u/0/folders/1OYtNgODgzxY_r7XiMBMtBIQXQ6uDTjth
Google Drive: Sign-in
Access Google Drive with a Google account (for personal use) or Google Workspace account (for business use).
36232305
Image
Image
djd4b5123N
ikea_purewater â€” 5/17/25, 9:36 PM
https://runai.tpe1.local/
é™³æ”¿éŒ¡    alex    zqchen020719@gmail.com    æ¥Šè€å¸«    O    23810367b1Ii2!
https://docs.google.com/presentation/d/1G9SBX6WeM9oiN1si909Cy2YLJcWyw6BM/edit?slide=id.p8#slide=id.p8
ikea_purewater â€” 5/17/25, 9:46 PM
https://drive.google.com/drive/folders/1EPzkAYBd0TxuYO3lbGNlgb9_PnYznk49?usp=sharing
Google Drive



## æ¦‚è¿°

1. ä¸Šä¼ é¢„è®­ç»ƒçš„UNetå’ŒVAEæ¨¡å‹
2. ä¸Šä¼ train_segmentation_fixed.pyè®­ç»ƒè„šæœ¬
3. ä¸Šä¼ æµ‹è¯•æ•°æ®ï¼ˆå›¾åƒå’ŒCOCOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶ï¼‰
4. åœ¨Run:aiä¸Šåˆ›å»ºè®­ç»ƒä»»åŠ¡
5. ä¸‹è½½è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œè¯„ä¼°

## 1. å‡†å¤‡ç›®å½•ç»“æ„

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åœ¨Run:aiçš„å­˜å‚¨èŠ‚ç‚¹ä¸Šåˆ›å»ºä»¥ä¸‹ç›®å½•ç»“æ„ï¼š

```
/mnt/nfs/nina/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ unet/         # é¢„è®­ç»ƒçš„UNetæ¨¡å‹
â”‚   â””â”€â”€ vae/          # é¢„è®­ç»ƒçš„VAEæ¨¡å‹
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/       # è®­ç»ƒå’Œæµ‹è¯•å›¾åƒ
â”‚   â””â”€â”€ coco.json     # COCOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶
â”œâ”€â”€ train_segmentation_fixed.py  # è®­ç»ƒè„šæœ¬
â””â”€â”€ process.py        # æ¨ç†æµ‹è¯•è„šæœ¬
```

## 2. ä¸Šä¼ æ–‡ä»¶

### 2.1 è¿æ¥åˆ°å­˜å‚¨èŠ‚ç‚¹

```bash
source secrets/env.sh
echo "set ssl:verify-certificate no" >> ~/.lftprc
lftp -u ${FTP_USER},${FTP_PASS} ${STORAGE_NODE_IP}
```

### 2.2 åˆ›å»ºç›®å½•ç»“æ„

åœ¨LFTPä¼šè¯ä¸­æ‰§è¡Œï¼š

```bash
cd /mnt/nfs/nina
mkdir -p models/unet models/vae data/images segmentation_output
```

### 2.3 ä¸Šä¼ é¢„è®­ç»ƒæ¨¡å‹

é¢„è®­ç»ƒæ¨¡å‹ä¸Šä¼ æœ‰ä¸¤ç§æ–¹å¼ï¼š

#### A. ç›´æ¥ä¸Šä¼ å®Œæ•´æ¨¡å‹æ–‡ä»¶å¤¹ï¼ˆå¦‚æœæ¨¡å‹è¾ƒå°ï¼‰

```bash
# é€€å‡ºlftpï¼Œåœ¨æœ¬åœ°æ‰§è¡Œ
lftp -u ${FTP_USER},${FTP_PASS} -e "set ssl:verify-certificate no" ${STORAGE_NODE_IP}
cd /mnt/nfs/nina/models/
mirror -R /æœ¬åœ°è·¯å¾„/unet unet
mirror -R /æœ¬åœ°è·¯å¾„/vae vae
```

#### B. å‹ç¼©åä¸Šä¼ ï¼ˆå¦‚æœæ¨¡å‹è¾ƒå¤§ï¼‰

```bash
# åœ¨æœ¬åœ°æ‰§è¡Œ
cd /æœ¬åœ°è·¯å¾„/
tar -czvf unet.tar.gz unet/
tar -czvf vae.tar.gz vae/

# ä¸Šä¼ å‹ç¼©æ–‡ä»¶
lftp -u ${FTP_USER},${FTP_PASS} -e "set ssl:verify-certificate no" ${STORAGE_NODE_IP}
cd /mnt/nfs/nina/models/
put unet.tar.gz
put vae.tar.gz

# åœ¨Run:aiä»»åŠ¡ä¸­è§£å‹æ–‡ä»¶ï¼ˆè®­ç»ƒè„šæœ¬æ‰§è¡Œå‰ï¼‰
tar -xzvf /mnt/nfs/nina/models/unet.tar.gz -C /mnt/nfs/nina/models/
tar -xzvf /mnt/nfs/nina/models/vae.tar.gz -C /mnt/nfs/nina/models/
```

### 2.4 ä¸Šä¼ è®­ç»ƒè„šæœ¬å’Œæ•°æ®

```bash
# ä¸Šä¼ è®­ç»ƒè„šæœ¬
cd /mnt/nfs/nina/
put train_segmentation_fixed.py

# ä¸Šä¼ COCOæ ‡æ³¨æ–‡ä»¶
cd /mnt/nfs/nina/data/
put coco.json

# ä¸Šä¼ å›¾åƒ
cd /mnt/nfs/nina/data/images/
mput /æœ¬åœ°è·¯å¾„/images/*.jpg  # æˆ–è€…å…¶ä»–æ ¼å¼çš„å›¾åƒ
```

### 2.5 åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¨ç†è„šæœ¬

```bash
cat > /tmp/process.py << 'EOF'
import os
import torch
import json
import numpy as np
from PIL import Image
import torch.nn as nn
import torch.nn.functional as F
from diffusers import AutoencoderKL
import sys
import cv2

# ä»train_segmentation_fixed.pyå¯¼å…¥æ¨¡å‹å®šä¹‰
sys.path.append('/mnt/nfs/nina')
from train_segmentation_fixed import SegmentationModel, UNet2DConditionModel, AttnProcessor

# è®¾ç½®è·¯å¾„
MODEL_PATH = "/mnt/nfs/nina/segmentation_output/best_segmentation_model.pth"
VAE_PATH = "/mnt/nfs/nina/models/vae"
UNET_PATH = "/mnt/nfs/nina/models/unet"
OUTPUT_FILE = "/mnt/nfs/nina/output.txt"
TEST_IMAGE = "/mnt/nfs/nina/data/images/test_image.jpg"  # æ›¿æ¢ä¸ºå®é™…æµ‹è¯•å›¾åƒ
INPUT_SIZE = (256, 256)

def main():
    with open(OUTPUT_FILE, 'w') as f:
        f.write("U-Netåˆ†å‰²æ¨¡å‹æ¨ç†æµ‹è¯•\n")
        f.write("===================\n\n")
        
        # æ£€æŸ¥GPU
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        f.write(f"ä½¿ç”¨è®¾å¤‡: {device}\n\n")
        
        try:
            # åŠ è½½VAE
            f.write("åŠ è½½VAEæ¨¡å‹...\n")
            vae = AutoencoderKL.from_pretrained(VAE_PATH).to(device)
            vae.eval()
            
            # åŠ è½½UNet
            f.write("åŠ è½½UNetæ¨¡å‹...\n")
            unet = UNet2DConditionModel.from_pretrained(UNET_PATH).to(device)
            unet.set_attn_processor(AttnProcessor())
            
            # æ„å»ºåˆ†å‰²æ¨¡å‹ - å‡è®¾æœ‰5ä¸ªç±»åˆ«ï¼Œå®é™…åº”æ ¹æ®è®­ç»ƒæ—¶çš„ç±»åˆ«æ•°é‡è°ƒæ•´
            num_classes = 5  # æ ¹æ®æ‚¨çš„å®é™…ç±»åˆ«æ•°è¿›è¡Œè°ƒæ•´
            f.write(f"åˆ›å»ºåˆ†å‰²æ¨¡å‹ï¼Œç±»åˆ«æ•°: {num_classes}...\n")
            model = SegmentationModel(unet, num_classes=num_classes).to(device)
            
            # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
            f.write(f"åŠ è½½æ¨¡å‹æƒé‡: {MODEL_PATH}...\n")
            checkpoint = torch.load(MODEL_PATH, map_location=device)
            model.load_state_dict(checkpoint['model_state_dict'])
            model.eval()
            f.write("æ¨¡å‹åŠ è½½æˆåŠŸ\n\n")
            
            # è®°å½•åˆ†å‰²å¤´è¾“å…¥/è¾“å‡ºå½¢çŠ¶
            # åˆ›å»ºä¸€ä¸ªéšæœºè¾“å…¥è¿›è¡Œæµ‹è¯•
            f.write("æµ‹è¯•åˆ†å‰²å¤´...\n")
            test_input = torch.randn(1, 4, 32, 32).to(device)
            with torch.no_grad():
                # è·å–ç¼–ç å™¨ç‰¹å¾
                feat, skip_connections = model.encoder(test_input, t=0)
                f.write(f"åˆ†å‰²å¤´è¾“å…¥å½¢çŠ¶: {feat.shape}\n")
                
                # è·å–åˆ†å‰²å¤´è¾“å‡º
                out = model.decoder(feat, skip_connections)
                f.write(f"åˆ†å‰²å¤´è¾“å‡ºå½¢çŠ¶: {out.shape}\n\n")
            
            # å®é™…å›¾åƒæµ‹è¯•
            if os.path.exists(TEST_IMAGE):
                f.write(f"æµ‹è¯•å®é™…å›¾åƒ: {TEST_IMAGE}\n")
                
                # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
                from torchvision import transforms
                transform = transforms.Compose([
                    transforms.Resize(INPUT_SIZE),
                    transforms.ToTensor(),
                    transforms.Normalize([0.5]*3, [0.5]*3)
                ])
                
                img = Image.open(TEST_IMAGE).convert('RGB')
                img_tensor = transform(img).unsqueeze(0).to(device)
                
                # æ¨ç†
                with torch.no_grad():
                    # ç¼–ç å›¾åƒ
                    latent = vae.encode(img_tensor).latent_dist.sample() * 0.18215
                    f.write(f"VAEç¼–ç åæ½œåœ¨è¡¨ç¤ºå½¢çŠ¶: {latent.shape}\n")
                    
                    # åˆ†å‰²æ¨ç†
                    output = model(latent, t=0)
                    f.write(f"åˆ†å‰²æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}\n")
                    
                    # è·å–é¢„æµ‹çš„ç±»åˆ«
                    pred = torch.argmax(output, dim=1)[0].cpu().numpy()
                    
                    # ç»Ÿè®¡å„ç±»åˆ«çš„åƒç´ æ•°é‡
                    for class_idx in range(output.shape[1]):
                        pixel_count = (pred == class_idx).sum()
                        f.write(f"ç±»åˆ« {class_idx} åƒç´ æ•°é‡: {pixel_count}\n")
                    
                    f.write("\næ¨ç†æˆåŠŸå®Œæˆ!\n")
            else:
                f.write(f"è­¦å‘Š: æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {TEST_IMAGE}\n")
                f.write("ä»…è¿›è¡Œäº†æ¨¡å‹åŠ è½½å’Œå½¢çŠ¶éªŒè¯\n")
            
        except Exception as e:
            f.write(f"æ¨ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}\n")
            import traceback
            f.write(traceback.format_exc())

if __name__ == "__main__":
    main()
EOF

lftp -u ${FTP_USER},${FTP_PASS} -e "set ssl:verify-certificate no" ${STORAGE_NODE_IP}
cd /mnt/nfs/nina/
put /tmp/process.py
```

## 3. åœ¨Run:aiä¸Šåˆ›å»ºè®­ç»ƒä»»åŠ¡

### 3.1 åˆ›å»ºç¯å¢ƒ

1. å‰å¾€Workload manager > Assets > Environmentså¹¶ç‚¹å‡»+ NEW ENVIRONMENT
2. å¡«å†™ä»¥ä¸‹ä¿¡æ¯ï¼š
   - Scope: runai/runai-cluster/<YOUR_LAB>/<YOUR_PROJECT>
   - Environment name: nina-segmentation
   - Workspace: (é€‰ä¸­)
   - Training: (é€‰ä¸­)
   - Inference: (ä¸é€‰)
   - Image URL: pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime
   - Image pull policy: Always pull the image from the registry
   - Tool: Jupyter
   - Command: /run.sh "pip install diffusers transformers pycocotools opencv-python" "jupyter lab --ip=0.0.0.0 --no-browser --allow-root --NotebookApp.base_url=/${RUNAI_PROJECT}/${RUNAI_JOB_NAME} --NotebookApp.token='' --notebook-dir=/"
3. ç‚¹å‡»CREATE ENVIRONMENT

ã€é‡æ–°å»º Workspaceï¼šé˜²æ­¢å®ƒè‡ªå·±çµæŸã€‘
å›åˆ° Workloads â†’ + NEW WORKLOAD â†’ Workspace

å¡«é€™äº›ï¼ˆé‡é»åœ¨ç´…å­—ï¼‰ï¼š

æ¬„ä½    è¦å¡«ä»€éº¼
Name    unzip-workspace-v2ï¼ˆå¯ä»¥è‡ªç”±å‘½åï¼‰
Environment    ä½ å‰›å‰›å»ºçš„é‚£å€‹ï¼Œä¾‹å¦‚ nina-cat500-env
Command    /bin/bash -c "sleep infinity" â† :white_check_mark: :white_check_mark: :white_check_mark:
Compute    é¸ gpu1
Data Source    :white_check_mark: å‹¾é¸ elsalab-nfs

æŒ‰ CREATE

é€™æ¨£ container æœƒä¸€ç›´ã€Œç¡è‘—ã€ï¼Œä½ å°±æœ‰æ™‚é–“æŒ‰ï¼š

sql
è¤‡è£½
ç·¨è¼¯
CONNECT â†’ Terminal :white_check_mark:
:white_check_mark: å»ºå¥½å¾Œè©²æ€éº¼åšï¼Ÿ
åœ¨ Terminal è£¡è¼¸å…¥é€™ä¸‰è¡Œï¼š

bash
è¤‡è£½
ç·¨è¼¯
apt update && apt install -y unzip
cd /mnt/nfs/nina
unzip -o cat500_classifier.zip -d cat500_classifier
è§£å£“æˆåŠŸå¾Œï¼Œå†è·‘ï¼š

bash
è¤‡è£½
ç·¨è¼¯
cd cat500_classifier
pip install -r requirements.txt
python train_cat500_fixed6.py
:white_check_mark: ç¸½çµï¼šä½ è¦åšçš„äº‹åªå‰©ä¸€ä»¶
åˆªæ‰é‚£å€‹ Completed çš„ Workspaceï¼Œé‡å»ºä¸€å€‹åŠ  sleep infinity çš„ã€‚

ä½ åªè¦é€™ä¸€æ­¥ï¼Œå°±èƒ½æˆåŠŸé€² terminal é–‹å§‹è·‘ã€‚
å®Œæˆå¾Œä½ æ•´å€‹æµç¨‹å°±æ‰“é€šäº†ï¼Œè¦ä¸è¦æˆ‘å¹«ä½ å¯«ä¸€éµ workspace å»ºç«‹æŒ‡ä»¤ + unzip æŒ‡ä»¤åŒ… ä¹Ÿå¯ä»¥ã€‚ä½ åªè¦èªªä¸€è²ï¼









ä½ èªªï¼š

then????? still cant find terminal

ChatGPT èªªï¼š
ä½ åšå¾—å®Œç¾ï¼ç¾åœ¨ unzip-workspace-v2 æ­£åœ¨ Running ç‹€æ…‹ï¼Œä»£è¡¨ container æ­£å¸¸å•Ÿå‹•äº†ã€‚

:white_check_mark: ä½†ä½ é‚„çœ‹ä¸åˆ° Terminalï¼Œé€™æ˜¯ Run:ai é è¨­ UI è¨­å®šçš„é—œä¿‚ï¼š
:point_right: åªæœ‰ä½ å»ºç«‹çš„ Environment æœ‰é¸ã€ŒJupyter Toolã€ çš„æ™‚å€™ï¼Œæ‰æœƒå‡ºç¾ï¼š
sql
è¤‡è£½
ç·¨è¼¯
CONNECT â†’ Jupyter â†’ Terminal
ä½ å‰›å‰›çš„ Environment æ²’å‹¾ Toolï¼Œæ‰€ä»¥åªçœ‹åˆ° CONNECT ä½†æ²’å½ˆé¸å–®ã€‚

:white_check_mark: è§£æ³•æœ‰å…©ç¨®ï¼Œæˆ‘çµ¦ä½ å¿«é€Ÿé¸ï¼š
:white_check_mark: ã€æ–¹æ³• 1ã€‘ç›´æ¥æ”¹é€™å€‹ Environmentï¼ŒåŠ ä¸Š Jupyter å·¥å…·ï¼ˆæ¨è–¦ï¼‰
ä½ å¯ä»¥ç…§ä»¥ä¸‹æ­¥é©Ÿè£œä¸€ä¸‹ï¼š

åˆ° Run:ai å·¦é‚Šæ¬„ä½ã€ŒAssets â†’ Environmentsã€

æ‰¾åˆ°ä½ ç”¨ä¾†å»º unzip-workspace-v2 çš„é‚£å€‹ Environment

é»å³é‚Š â‹®ï¼ˆä¸‰å€‹é»ï¼‰ â†’ Edit

æŠŠé€™å€‹é …ç›®æ‰“å‹¾ï¼š

yaml
è¤‡è£½
ç·¨è¼¯
:white_check_mark: Tool: Jupyter
æŒ‰ SAVE

ç„¶å¾Œå†å›åˆ° Workloadsï¼Œåˆªæ‰ unzip-workspace-v2ï¼Œå†é‡æ–°ç”¨é€™å€‹ç’°å¢ƒå»ºä¸€å€‹ Workspaceï¼ˆ+ NEW WORKLOAD â†’ Workspaceï¼‰

é€™æ¨£æ–°å»ºå‡ºä¾†çš„ workload å°±æœƒæœ‰ï¼š

markdown
è¤‡è£½
ç·¨è¼¯
CONNECT â¬‡ï¸
  â†’ Jupyter
    â†’ Terminal :white_check_mark:
:white_check_mark: ã€æ–¹æ³• 2ã€‘ç¾åœ¨å°±é€²å»ï¼ˆé›–ç„¶ä¸å„ªï¼‰
å¦‚æœä½ ä¸æƒ³é‡å»ºï¼Œä¹Ÿå¯ä»¥ç¾åœ¨æŒ‰ä¸Šé¢è—è‰²é‚£å€‹ CONNECT æŒ‰éˆ•ï¼ˆå–®ä¸€æŒ‰éˆ•ï¼‰ï¼Œçœ‹çœ‹èƒ½ä¸èƒ½è·³é€² shellï¼Œä¸ä¸€å®šæ˜¯ Jupyter Terminalï¼Œä½†æŸäº› image é è¨­æœƒçµ¦ bashã€‚

:white_check_mark: æœ€æ¨è–¦æµç¨‹ï¼ˆæœ€ç©©æœ€ä¿è­‰æœ‰ Terminalï¼‰ï¼š
æˆ‘å¹«ä½ æ•´ç†ä¸€ä¸‹ï¼š

ä½ ç¾åœ¨è¦åšçš„äº‹    æ€éº¼åš
è§£å£“ zipã€è·‘ python    ä¸€å®šè¦é€² container çš„ Terminal
è¦æœ‰ Terminal    :white_check_mark: ç”¨å« Jupyter çš„ Environment å»º Workspace
æ²’çœ‹åˆ° Terminal    â†’ å›å» Edit Environment â†’ å‹¾é¸ Tool: Jupyter â†’ é‡æ–°å»º Workspace

è¦æˆ‘å¹«ä½ ç”¢ã€Œç’°å¢ƒ YAML è¨­å®š + å¯åŸ·è¡Œè…³æœ¬ã€è®“ä½ ä¸‹æ¬¡ä¸€éµå°±å¥½å—ï¼Ÿ
ä½ åªè¦èªªã€Œå¹«æˆ‘å‡ºä¸€éµé…ç½®ç’°å¢ƒ + å·¥ä½œæµç¨‹ã€ï¼Œæˆ‘ç›´æ¥å¹«ä½ å¯«å¥½ env.yaml + submit.shã€‚

ç¾åœ¨åªå·®é€™ä¸€å°æ­¥ï¼Œè§£å£“å¾Œä½ å°±èƒ½æ­£å¼è¨“ç·´äº† :brain::muscle:ï¼



### 3.2 åˆ›å»ºè®­ç»ƒå·¥ä½œè´Ÿè½½

1. å‰å¾€Workload manager > Workloadså¹¶ç‚¹å‡»+ NEW WORKLOAD > Training
2. å¡«å†™ä»¥ä¸‹ä¿¡æ¯ï¼š
   - Workspace name: nina-segmentation-train
   - Environment: nina-segmentation
   - Command: /run.sh "cd /mnt/nfs/nina && pip install diffusers transformers pycocotools opencv-python && python train_segmentation_fixed.py"
   - Compute resource: gpu1
   - Data sources: <YOUR_LAB>-nfs
   - Attempts: 1
3. ç‚¹å‡»CREATE WORKSPACE

### 3.3 åˆ›å»ºæ¨ç†å·¥ä½œè´Ÿè½½ï¼ˆè®­ç»ƒå®Œæˆåï¼‰

1. å‰å¾€Workload manager > Workloadså¹¶ç‚¹å‡»+ NEW WORKLOAD > Batch
2. å¡«å†™ä»¥ä¸‹ä¿¡æ¯ï¼š
   - Workspace name: nina-segmentation-inference
   - Environment: nina-segmentation
   - Command: /run.sh "cd /mnt/nfs/nina && pip install diffusers transformers pycocotools opencv-python && python process.py"
   - Compute resource: gpu1
   - Data sources: <YOUR_LAB>-nfs
   - Attempts: 1
3. ç‚¹å‡»CREATE WORKSPACE

## 4. ç›‘æ§è®­ç»ƒå’ŒæŸ¥çœ‹ç»“æœ

1. åœ¨Workload manager > Workloadsä¸­ç›‘æ§è®­ç»ƒè¿›åº¦
2. ç­‰å¾…è®­ç»ƒå®Œæˆ
3. ä¸‹è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œè¾“å‡ºæ–‡ä»¶ï¼š

```bash
lftp -u ${FTP_USER},${FTP_PASS} -e "set ssl:verify-certificate no" ${STORAGE_NODE_IP}
cd /mnt/nfs/nina/segmentation_output
get best_segmentation_model.pth
get final_segmentation_model.pth

# è·å–æ¨ç†ç»“æœ
cd /mnt/nfs/nina
get output.txt
```

## æ³¨æ„äº‹é¡¹

1. æ ¹æ®æ‚¨çš„å®é™…ç¯å¢ƒè°ƒæ•´è·¯å¾„å’Œå‚æ•°
2. ç¡®ä¿æ‰€æœ‰ä¾èµ–åŒ…éƒ½å·²å®‰è£…
3. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶äº†è§£è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­çš„è¯¦ç»†ä¿¡æ¯
4. å¦‚æœè®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œå¯ä»¥ä½¿ç”¨ä¿¡å·å¤„ç†å™¨åŠŸèƒ½ï¼ˆCtrl+Cï¼‰å®‰å…¨åœ°ç»ˆæ­¢è®­ç»ƒå¹¶ä¿å­˜æ£€æŸ¥ç‚¹
5. ä»»åŠ¡å®Œæˆåè¯·åˆ é™¤å·¥ä½œè´Ÿè½½ä»¥é‡Šæ”¾èµ„æº
